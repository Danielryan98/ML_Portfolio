{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ageron/handson-ml2/blob/master/06_decision_trees.ipynb <br/>\n",
    "https://github.com/ageron/handson-ml2/blob/master/04_training_linear_models.ipynb\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is \n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_size = 512\n",
    "train_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_train.csv'))\n",
    "test_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_test.csv'))\n",
    "\n",
    "X_train = train_data[:, 1:785]\n",
    "y_train = train_data[:, 0]\n",
    "X_test = test_data[:, 1:785]\n",
    "y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_y_train_pred = cross_val_predict(clf, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4490,   37,  128,  256,   55,   12,  937,    4,   77,    4],\n",
       "       [  43, 5682,   15,  173,   35,    3,   39,    0,    8,    2],\n",
       "       [ 148,   22, 4096,  102,  882,   11,  677,    0,   57,    5],\n",
       "       [ 273,  163,  106, 4786,  324,   15,  286,    2,   43,    2],\n",
       "       [  64,   30,  942,  294, 3933,    5,  681,    1,   48,    2],\n",
       "       [  15,    8,    6,   14,    2, 5376,   11,  348,   63,  157],\n",
       "       [ 922,   39,  742,  239,  644,    9, 3260,    2,  137,    6],\n",
       "       [   0,    0,    0,    2,    1,  365,    1, 5227,   31,  373],\n",
       "       [  55,   13,   85,   44,   62,   85,  139,   34, 5455,   28],\n",
       "       [   5,    1,    7,   10,    7,  156,    7,  358,   25, 5424]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class 0: TP=4490 | FP=1510 | TN=52475 (60000-TP+FP+FN) | FN=1525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cnf_matrix = confusion_matrix(y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_FP = cv_cnf_matrix.sum(axis=0) - np.diag(cv_cnf_matrix) \n",
    "CV_FN = cv_cnf_matrix.sum(axis=1) - np.diag(cv_cnf_matrix)\n",
    "CV_TP = np.diag(cv_cnf_matrix)\n",
    "CV_TN = cv_cnf_matrix.sum() - (CV_FP + CV_FN + CV_TP)\n",
    "CV_FP = CV_FP.astype(float)\n",
    "CV_FN = CV_FN.astype(float)\n",
    "CV_TP = CV_TP.astype(float)\n",
    "CV_TN = CV_TN.astype(float)\n",
    "\n",
    "avg_cv_FP=0\n",
    "avg_cv_FN=0\n",
    "avg_cv_TP=0\n",
    "avg_cv_TN=0\n",
    "\n",
    "for i in CV_FP:\n",
    "    avg_cv_FP+=i\n",
    "    \n",
    "for i in CV_FN:\n",
    "    avg_cv_FN+=i\n",
    "    \n",
    "for i in CV_TP:\n",
    "    avg_cv_TP+=i\n",
    "\n",
    "for i in CV_TN:\n",
    "    avg_cv_TN+=i\n",
    "    \n",
    "avg_cv_FP = avg_cv_FP/10\n",
    "avg_cv_FN = avg_cv_FN/10\n",
    "avg_cv_TP = avg_cv_TP/10\n",
    "avg_cv_TN = avg_cv_TN/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0, 6000,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0, 6000,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0, 6000,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0, 6000,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0, 6000,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0, 6000,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 6000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0, 6000,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 6000]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see that it has 60000 TP because its the set it trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnf_matrix = confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FP = train_cnf_matrix.sum(axis=0) - np.diag(train_cnf_matrix) \n",
    "train_FN = train_cnf_matrix.sum(axis=1) - np.diag(train_cnf_matrix)\n",
    "train_TP = np.diag(train_cnf_matrix)\n",
    "train_TN = train_cnf_matrix.sum() - (train_FP + train_FN + train_TP)\n",
    "train_FP = train_FP.astype(float)\n",
    "train_FN = train_FN.astype(float)\n",
    "train_TP = train_TP.astype(float)\n",
    "train_TN = train_TN.astype(float)\n",
    "\n",
    "avg_train_FP=0\n",
    "avg_train_FN=0\n",
    "avg_train_TP=0\n",
    "avg_train_TN=0\n",
    "\n",
    "for i in train_FP:\n",
    "    avg_train_FP+=i\n",
    "    \n",
    "for i in train_FN:\n",
    "    avg_train_FN+=i\n",
    "    \n",
    "for i in train_TP:\n",
    "    avg_train_TP+=i\n",
    "\n",
    "for i in train_TN:\n",
    "    avg_train_TN+=i\n",
    "    \n",
    "avg_train_FP = avg_train_FP/10\n",
    "avg_train_FN = avg_train_FN/10\n",
    "avg_train_TP = avg_train_TP/10\n",
    "avg_train_TN = avg_train_TN/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[732,   6,  19,  41,   7,   3, 175,   3,  14,   0],\n",
       "       [  4, 960,   4,  19,   7,   0,   4,   0,   2,   0],\n",
       "       [ 26,   5, 683,  17, 137,   3, 118,   0,  10,   1],\n",
       "       [ 44,  28,  15, 813,  60,   2,  36,   0,   2,   0],\n",
       "       [  5,   4, 146,  50, 690,   1,  93,   0,  10,   1],\n",
       "       [  1,   1,   1,   0,   1, 873,   2,  66,  21,  34],\n",
       "       [166,  12, 105,  39, 102,   1, 561,   0,  13,   1],\n",
       "       [  0,   0,   0,   0,   0,  56,   0, 857,   8,  79],\n",
       "       [ 19,   1,  16,   7,  17,  10,  20,   8, 898,   4],\n",
       "       [  1,   0,   0,   1,   1,  25,   2,  69,   5, 896]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm = confusion_matrix(y_test, y_test_pred)\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7963 TP\n",
    "\n",
    "class 0: TP=732 | FP=268 (6+19+41+7+3+175+3+14+0) | TN=8734 (60000-TP+FP+FN) or (960+5+28+4+...+4+683+15+146+...+19+17+...) | FN=266 (4+26+44+5+1+166+19+1)\n",
    "\n",
    "class 1: TP=960 | FP=40 | TN=8943 | FN=57\n",
    "\n",
    "class 2: TP=683 | FP=317 | TN=8694 | FN=306\n",
    "\n",
    "class 3: TP=813 | FP=187 | TN=8826 | FN=174\n",
    "\n",
    "class 4: TP=690 | FP=310 | TN=8668 | FN=332\n",
    "\n",
    "class 5: TP=873 | FP=127 | TN=8899 | FN=101\n",
    "\n",
    "class 6: TP=561 | FP=439 | TN=8550 | FN=450\n",
    "\n",
    "class 7: TP=857 | FP=143 | TN=8854 | FN=146\n",
    "\n",
    "class 8: TP=898 | FP=102 | TN=8915 | FN=85\n",
    "\n",
    "class 9: TP=896 | FP=104 | TN=8880 | FN=120\n",
    "\n",
    "With the whole set taken into account there are 7963 TP so accuracy is 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set displays an okay matrix, pretty good results, 1k items per class so 960tp on class 1 is great, seems to nail class 1 pretty well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnf_matrix = confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FP = test_cnf_matrix.sum(axis=0) - np.diag(test_cnf_matrix) \n",
    "test_FN = test_cnf_matrix.sum(axis=1) - np.diag(test_cnf_matrix)\n",
    "test_TP = np.diag(test_cnf_matrix)\n",
    "test_TN = test_cnf_matrix.sum() - (test_FP + test_FN + test_TP)\n",
    "test_FP = test_FP.astype(float)\n",
    "test_FN = test_FN.astype(float)\n",
    "test_TP = test_TP.astype(float)\n",
    "test_TN = test_TN.astype(float)\n",
    "\n",
    "avg_test_FP=0\n",
    "avg_test_FN=0\n",
    "avg_test_TP=0\n",
    "avg_test_TN=0\n",
    "\n",
    "for i in test_FP:\n",
    "    avg_test_FP+=i\n",
    "    \n",
    "for i in test_FN:\n",
    "    avg_test_FN+=i\n",
    "    \n",
    "for i in test_TP:\n",
    "    avg_test_TP+=i\n",
    "\n",
    "for i in test_TN:\n",
    "    avg_test_TN+=i\n",
    "    \n",
    "avg_test_FP = avg_test_FP/10\n",
    "avg_test_FN = avg_test_FN/10\n",
    "avg_test_TP = avg_test_TP/10\n",
    "avg_test_TN = avg_test_TN/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% accuracy for cross validation, 80% accuracy with decision tree, both worse than Categorical Naive Bayes which had 87% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7954833333333333\n",
      "47729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_train, cross_val_y_train_pred))\n",
    "\n",
    "print(accuracy_score(y_train, cross_val_y_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7963\n",
      "7963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specificity\n",
    "\n",
    "TN / (TN + FP) How sensitive is the classifier to the negative cases? - A highly specific test for cancer: if \"YES\" then you can be sure it's \"YES\". Closer to 1 means less false positives. 100% Specificity misses some true positives but in return provides no false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9772759259259259"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_cv_TN/(avg_cv_TN+avg_cv_FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_train_TN/(avg_train_TN+avg_train_FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9773666666666666"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_test_TN/(avg_test_TN+avg_test_FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "98% specificity for cv is incredible in comparison to 78% for Categorical Naive Bayes. Decision Tree Test also has 98%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall\n",
    "Recall is intuitevely the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The best value is 1, and the worst value is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision = TP / (TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43% for Categorical Naive Bayes, so a big jump to 80% in both cross validation and test decision tree. So it classifies positive cases with 80% confidence, every 4 in 5 is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954833333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train, cross_val_y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train, y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7963"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_test_pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recall = TP / (TP+FN)\n",
    "Similar to sensitivity (how sensitive is our classifier to the true cases? closer to 1 when theres no false negatives) with 100% sensitivity you catch all cases that could be true, so there will be more false postitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954833333333333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, cross_val_y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7963"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_test_pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall for Categorical Naive Bayes was .95 which was a really sensitive classifier, this time it is .75 so less sensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 = 2 / ((1 / precision) + (1 / recall)) = 2 x ((precision x recall) / (precision + recall)) = TP / (TP + ((FN + FP) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954833333333333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train, cross_val_y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7963"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_test_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_score(clf, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8868333333333334"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_score, average='macro', multi_class='ovo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the decision tree generalize well to the new data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree does not generalize well to the new data, but in comparison to cross validation, it matches its results for all performance metrices. It is therefore that the decision tree is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with various tree parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier(random_state=42, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred2 = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   6,   0,   0, 967,   0,   0,  13,   0,  14],\n",
       "       [  0, 840,   0,   0, 155,   0,   0,   2,   0,   3],\n",
       "       [  0,  12,   0,   0, 971,   0,   0,   7,   0,  10],\n",
       "       [  0,  11,   0,   0, 964,   0,   0,   2,   0,  23],\n",
       "       [  0,   1,   0,   0, 996,   0,   0,   3,   0,   0],\n",
       "       [  0,  29,   0,   0,  45,   0,   0, 691,   0, 235],\n",
       "       [  0,  13,   0,   0, 973,   0,   0,  10,   0,   4],\n",
       "       [  0,   0,   0,   0,   3,   0,   0, 866,   0, 131],\n",
       "       [  0,  11,   0,   0, 682,   0,   0,  42,   0, 265],\n",
       "       [  0,   0,   0,   0,  50,   0,   0, 109,   0, 841]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm2 = confusion_matrix(y_test, y_test_pred2)\n",
    "confusion_matrix(y_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnf_matrix2 = confusion_matrix(y_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FP2 = test_cnf_matrix2.sum(axis=0) - np.diag(test_cnf_matrix2) \n",
    "test_FN2 = test_cnf_matrix2.sum(axis=1) - np.diag(test_cnf_matrix2)\n",
    "test_TP2 = np.diag(test_cnf_matrix2)\n",
    "test_TN2 = test_cnf_matrix2.sum() - (test_FP2 + test_FN2 + test_TP2)\n",
    "test_FP2 = test_FP2.astype(float)\n",
    "test_FN2 = test_FN2.astype(float)\n",
    "test_TP2 = test_TP2.astype(float)\n",
    "test_TN2 = test_TN2.astype(float)\n",
    "\n",
    "avg_test_FP2=0\n",
    "avg_test_FN2=0\n",
    "avg_test_TP2=0\n",
    "avg_test_TN2=0\n",
    "\n",
    "for i in test_FP2:\n",
    "    avg_test_FP2+=i\n",
    "    \n",
    "for i in test_FN2:\n",
    "    avg_test_FN2+=i\n",
    "    \n",
    "for i in test_TP2:\n",
    "    avg_test_TP2+=i\n",
    "\n",
    "for i in test_TN2:\n",
    "    avg_test_TN2+=i\n",
    "    \n",
    "avg_test_FP2 = avg_test_FP2/10\n",
    "avg_test_FN2 = avg_test_FN2/10\n",
    "avg_test_TP2 = avg_test_TP2/10\n",
    "avg_test_TN2 = avg_test_TN2/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3543\n",
      "3543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred2))\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred2, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9282555555555555"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_test_TN2/(avg_test_TN2+avg_test_FP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3543"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_test_pred2, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3543"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_test_pred2, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35429999999999995"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_test_pred2, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Depth Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the results of the major metrics that reducing the max depth of the decision tree to 2 has a negative impact on the classifiers ability to accuractely classify unseen data. This is because by having a depth of 2 it is only allowing for 4 leaf nodes in total, and therefore it can only classify 4 different classes. If I was to up the depth too much, the classifier wouldn't perform as well as it would have too many choices, but in this case, it is over simplifying the classifications to two classes only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Threshold for Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = DecisionTreeClassifier(random_state=42, ccp_alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=1.0, random_state=42)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred3 = clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1000,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm3 = confusion_matrix(y_test, y_test_pred3)\n",
    "confusion_matrix(y_test, y_test_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Threshold for Pruning Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the lowest cost label is 0, it classifies as 0 everytime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting nodes (children not leafs) into x nodes, so a child node will be split into 6 here, and each of them 6 will either be split into another 6 or have 2 leaf nodes. My initial understanding tells me that a high split will return poor results because it will have too many to choose from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min split = 6 (deafault is 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = DecisionTreeClassifier(random_state=42, min_samples_split=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(min_samples_split=6, random_state=42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred4 = clf4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[756,   7,  24,  41,  10,   2, 146,   1,  13,   0],\n",
       "       [  4, 963,   3,  16,   5,   0,   7,   0,   2,   0],\n",
       "       [ 24,   5, 680,   9, 148,   3, 122,   0,   8,   1],\n",
       "       [ 54,  30,  20, 809,  49,   1,  35,   0,   2,   0],\n",
       "       [ 11,   6, 164,  47, 673,   1,  89,   0,   8,   1],\n",
       "       [  3,   0,   1,   0,   2, 874,   3,  65,  19,  33],\n",
       "       [170,  12, 103,  37, 109,   1, 553,   0,  15,   0],\n",
       "       [  0,   0,   0,   0,   0,  61,   0, 862,   4,  73],\n",
       "       [ 16,   2,  26,   6,  13,  10,  16,   7, 900,   4],\n",
       "       [  2,   0,   0,   1,   1,  28,   2,  70,   5, 891]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm4 = confusion_matrix(y_test, y_test_pred4)\n",
    "confusion_matrix(y_test, y_test_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnf_matrix4 = confusion_matrix(y_test, y_test_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FP4 = test_cnf_matrix4.sum(axis=0) - np.diag(test_cnf_matrix4) \n",
    "test_FN4 = test_cnf_matrix4.sum(axis=1) - np.diag(test_cnf_matrix4)\n",
    "test_TP4 = np.diag(test_cnf_matrix4)\n",
    "test_TN4 = test_cnf_matrix4.sum() - (test_FP4 + test_FN4 + test_TP4)\n",
    "test_FP4 = test_FP4.astype(float)\n",
    "test_FN4 = test_FN4.astype(float)\n",
    "test_TP4 = test_TP4.astype(float)\n",
    "test_TN4 = test_TN4.astype(float)\n",
    "\n",
    "avg_test_FP4=0\n",
    "avg_test_FN4=0\n",
    "avg_test_TP4=0\n",
    "avg_test_TN4=0\n",
    "\n",
    "for i in test_FP4:\n",
    "    avg_test_FP4+=i\n",
    "    \n",
    "for i in test_FN4:\n",
    "    avg_test_FN4+=i\n",
    "    \n",
    "for i in test_TP4:\n",
    "    avg_test_TP4+=i\n",
    "\n",
    "for i in test_TN4:\n",
    "    avg_test_TN4+=i\n",
    "    \n",
    "avg_test_FP4 = avg_test_FP4/10\n",
    "avg_test_FN4 = avg_test_FN4/10\n",
    "avg_test_TP4 = avg_test_TP4/10\n",
    "avg_test_TN4 = avg_test_TN4/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7961\n",
      "7961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred4))\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred4, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9773444444444445"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_test_TN4/(avg_test_TN4+avg_test_FP4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7961"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_test_pred4, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7961"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_test_pred4, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7961"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_test_pred4, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Split = 6 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it can be seen that with a sample split of 6, the accuracy is as good as it was with default split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Split = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5 = DecisionTreeClassifier(random_state=42, min_samples_split=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(min_samples_split=40000, random_state=42)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred5 = clf5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   6,   0,   0, 967,   0,   0,  27,   0,   0],\n",
       "       [  0, 840,   0,   0, 155,   0,   0,   5,   0,   0],\n",
       "       [  0,  12,   0,   0, 971,   0,   0,  17,   0,   0],\n",
       "       [  0,  11,   0,   0, 964,   0,   0,  25,   0,   0],\n",
       "       [  0,   1,   0,   0, 996,   0,   0,   3,   0,   0],\n",
       "       [  0,  29,   0,   0,  45,   0,   0, 926,   0,   0],\n",
       "       [  0,  13,   0,   0, 973,   0,   0,  14,   0,   0],\n",
       "       [  0,   0,   0,   0,   3,   0,   0, 997,   0,   0],\n",
       "       [  0,  11,   0,   0, 682,   0,   0, 307,   0,   0],\n",
       "       [  0,   0,   0,   0,  50,   0,   0, 950,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm5 = confusion_matrix(y_test, y_test_pred5)\n",
    "confusion_matrix(y_test, y_test_pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Split = 40000 conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the above matrix that with a split of 40000 the algorithm performs poorly, as there are 10 classes and it is only classifying images as one of three: class 1, class 4, and class 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Splitter (default = best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6 = DecisionTreeClassifier(random_state=42, splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42, splitter='random')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred6 = clf6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[732,   7,  29,  38,  14,   4, 159,   1,  16,   0],\n",
       "       [  7, 961,   4,  16,   5,   1,   5,   0,   1,   0],\n",
       "       [ 26,   4, 675,  18, 141,   1, 130,   1,   3,   1],\n",
       "       [ 42,  39,  17, 800,  43,   2,  46,   0,  11,   0],\n",
       "       [  9,   3, 139,  44, 659,   1, 134,   0,  10,   1],\n",
       "       [  2,   1,   0,   2,   3, 875,   4,  66,  13,  34],\n",
       "       [168,   6, 100,  35, 104,   3, 563,   0,  19,   2],\n",
       "       [  0,   0,   0,   0,   0,  62,   0, 863,   5,  70],\n",
       "       [  5,   2,  19,  13,  11,  16,  19,  10, 904,   1],\n",
       "       [  0,   1,   0,   0,   1,  18,   0,  58,   3, 919]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm6 = confusion_matrix(y_test, y_test_pred6)\n",
    "confusion_matrix(y_test, y_test_pred6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Leaf Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Leaf Nodes Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7 = DecisionTreeClassifier(random_state=42, max_leaf_nodes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_leaf_nodes=2, random_state=42)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred7 = clf7.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 973,   0,   0,   0,   0,   0,  27,   0,   0],\n",
       "       [  0, 995,   0,   0,   0,   0,   0,   5,   0,   0],\n",
       "       [  0, 983,   0,   0,   0,   0,   0,  17,   0,   0],\n",
       "       [  0, 975,   0,   0,   0,   0,   0,  25,   0,   0],\n",
       "       [  0, 997,   0,   0,   0,   0,   0,   3,   0,   0],\n",
       "       [  0,  74,   0,   0,   0,   0,   0, 926,   0,   0],\n",
       "       [  0, 986,   0,   0,   0,   0,   0,  14,   0,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0, 997,   0,   0],\n",
       "       [  0, 693,   0,   0,   0,   0,   0, 307,   0,   0],\n",
       "       [  0,  50,   0,   0,   0,   0,   0, 950,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm7 = confusion_matrix(y_test, y_test_pred7)\n",
    "confusion_matrix(y_test, y_test_pred7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only classifies as either class 1 or class 7, this is because only 2 leaf nodes are allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 200000 Leaf Nodes Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf8 = DecisionTreeClassifier(random_state=42, max_leaf_nodes=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_leaf_nodes=200000, random_state=42)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf8.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred8 = clf8.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[738,   6,  18,  41,   8,   2, 169,   1,  17,   0],\n",
       "       [  9, 963,   4,  16,   2,   0,   4,   0,   2,   0],\n",
       "       [ 25,   3, 675,  17, 144,   2, 120,   0,  12,   2],\n",
       "       [ 49,  24,  20, 810,  53,   3,  36,   0,   5,   0],\n",
       "       [  7,   5, 147,  47, 685,   0, 103,   0,   5,   1],\n",
       "       [  3,   1,   1,   1,   2, 872,   2,  60,  22,  36],\n",
       "       [171,   9, 104,  40, 104,   1, 554,   0,  17,   0],\n",
       "       [  0,   0,   0,   2,   0,  53,   1, 867,   2,  75],\n",
       "       [ 17,   1,  17,   3,  13,  12,  23,  10, 902,   2],\n",
       "       [  3,   0,   0,   1,   1,  19,   2,  71,   7, 896]], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm8 = confusion_matrix(y_test, y_test_pred8)\n",
    "confusion_matrix(y_test, y_test_pred8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 200K leaf nodes conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initially thought that it would be more accurate, but the matrix looks similar to that of the original algorithm. This will be because the max_split default is 2, and therefore the child nodes allow for the correct path, the only decision it has to make is on the leaf nodes, and it probably isn't using the full 200k leaf nodes allowed. If I were to change the max_split in combination with max leaf nodes to a really high number, the results would be bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test + 30% of Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_size = 512\n",
    "train_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_train.csv'))\n",
    "test_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_test.csv'))\n",
    "\n",
    "X_train = train_data[:, 1:785]\n",
    "y_train = train_data[:, 0]\n",
    "X_test = test_data[:, 1:785]\n",
    "y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_percent_X_train = X_train[0:18000]\n",
    "thirty_percent_y_train = y_train[0:18000]\n",
    "\n",
    "X_test_train = np.concatenate((X_test, thirty_percent_X_train), axis=0)\n",
    "y_test_train = np.concatenate((y_test, thirty_percent_y_train), axis=0)\n",
    "\n",
    "seventy_percent_X_train = X_train[18000:]\n",
    "seventy_percent_y_train = y_train[18000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n",
      "(28000,)\n",
      "(42000, 784)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_train.shape)\n",
    "print(y_test_train.shape)\n",
    "print(seventy_percent_X_train.shape)\n",
    "print(seventy_percent_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(seventy_percent_X_train, seventy_percent_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_y_train_pred = cross_val_predict(clf, seventy_percent_X_train, seventy_percent_y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cnf_matrix = confusion_matrix(seventy_percent_y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of 70% of Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7838571428571428\n",
      "32922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(seventy_percent_y_train, cross_val_y_train_pred))\n",
    "\n",
    "print(accuracy_score(seventy_percent_y_train, cross_val_y_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(seventy_percent_y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of Test + 30% of Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_train_pred = clf.predict(X_test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2114,   13,   84,  140,   37,    3,  429,    0,   47,    1],\n",
       "       [  19, 2664,   12,   54,   21,    0,   26,    0,    4,    0],\n",
       "       [  76,   14, 1872,   54,  386,    5,  321,    0,   30,    1],\n",
       "       [ 135,  106,   65, 2210,  146,    4,  126,    0,   22,    1],\n",
       "       [  26,   10,  383,  145, 1852,    2,  293,    0,   26,    1],\n",
       "       [   6,    3,    4,    9,    1, 2479,    4,  171,   33,   85],\n",
       "       [ 435,   18,  389,  106,  279,    7, 1510,    0,   61,    2],\n",
       "       [   0,    0,    0,    0,    1,  155,    0, 2467,   15,  217],\n",
       "       [  45,    6,   36,   34,   22,   22,   59,   24, 2515,   19],\n",
       "       [   4,    0,    3,    5,    0,   85,    6,  183,   14, 2481]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm = confusion_matrix(y_test_train, y_test_train_pred)\n",
    "confusion_matrix(y_test_train, y_test_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7915714285714286\n",
      "22164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test_train, y_test_train_pred))\n",
    "\n",
    "print(accuracy_score(y_test_train, y_test_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_test_train, y_test_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy was slightly higher on the test + train set using decision tree classifier in comparison to 70% of train set with cross validation. That will be because the cross-validation has less images to train on now, and it will get worse as it has less and less to train on, as it will lead to overfitting, since it has less information to go off. The decision tree classifier saw no change in accuracy in comparison to the original test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test + 60% of Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_size = 512\n",
    "train_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_train.csv'))\n",
    "test_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_test.csv'))\n",
    "\n",
    "X_train = train_data[:, 1:785]\n",
    "y_train = train_data[:, 0]\n",
    "X_test = test_data[:, 1:785]\n",
    "y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixty_percent_X_train = X_train[0:36000]\n",
    "sixty_percent_y_train = y_train[0:36000]\n",
    "\n",
    "X_test_train = np.concatenate((X_test, sixty_percent_X_train), axis=0)\n",
    "y_test_train = np.concatenate((y_test, sixty_percent_y_train), axis=0)\n",
    "\n",
    "fourty_percent_X_train = X_train[36000:]\n",
    "fourty_percent_y_train = y_train[36000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46000, 784)\n",
      "(46000,)\n",
      "(24000, 784)\n",
      "(24000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_train.shape)\n",
    "print(y_test_train.shape)\n",
    "print(fourty_percent_X_train.shape)\n",
    "print(fourty_percent_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(fourty_percent_X_train, fourty_percent_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_y_train_pred = cross_val_predict(clf, fourty_percent_X_train, fourty_percent_y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cnf_matrix = confusion_matrix(fourty_percent_y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of 40% Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7712083333333334\n",
      "18509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(fourty_percent_y_train, cross_val_y_train_pred))\n",
    "\n",
    "print(accuracy_score(fourty_percent_y_train, cross_val_y_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(fourty_percent_y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of Test + 60% Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_train_pred = clf.predict(X_test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3322,   43,  113,  226,   45,   17,  764,    6,   73,    5],\n",
       "       [  43, 4324,   20,  145,   20,    3,   30,    0,   10,    0],\n",
       "       [ 133,   28, 3050,  101,  671,    9,  531,    3,   73,    6],\n",
       "       [ 245,  140,   92, 3623,  240,   14,  201,    0,   35,    4],\n",
       "       [  72,   31,  679,  266, 2931,    4,  523,    2,   40,    3],\n",
       "       [  23,    7,    2,   24,    3, 3913,   18,  328,   86,  157],\n",
       "       [ 672,   31,  596,  231,  528,   13, 2463,    5,  110,    4],\n",
       "       [   0,    0,    1,    2,    0,  312,    1, 3933,   24,  372],\n",
       "       [  89,   13,   62,   43,   46,   57,  119,   33, 4092,   15],\n",
       "       [  12,    3,    4,    6,    4,  130,    5,  329,   28, 4092]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm = confusion_matrix(y_test_train, y_test_train_pred)\n",
    "confusion_matrix(y_test_train, y_test_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7770217391304348\n",
      "35743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test_train, y_test_train_pred))\n",
    "\n",
    "print(accuracy_score(y_test_train, y_test_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_test_train, y_test_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of cv on 40% of training set saw a further decrease in accuracy, almost to the point now where it wrongly classifies every 1 in 4. Accuracy of Test + 60% train also saw a decrease in accuracy, this is because the classifier was fitted using the unseen other 40% of the training set, and therefore, overfitting is beginning to occur because there is way more unseen data that hasnt came up in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 512\n",
    "train_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_train.csv'))\n",
    "test_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_test.csv'))\n",
    "\n",
    "X_train = train_data[:, 1:785]\n",
    "y_train = train_data[:, 0]\n",
    "X_test = test_data[:, 1:785]\n",
    "y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_y_train_pred = cross_val_predict(clf, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5208,    2,   72,  197,   23,    2,  450,    0,   46,    0],\n",
       "       [  17, 5794,   24,  128,   11,    1,   22,    0,    3,    0],\n",
       "       [  50,    1, 4913,   56,  662,    2,  283,    0,   33,    0],\n",
       "       [ 108,   15,   45, 5507,  190,    0,  123,    0,   12,    0],\n",
       "       [  10,    7,  471,  228, 4991,    1,  273,    0,   19,    0],\n",
       "       [   0,    0,    0,    1,    0, 5770,    1,  154,   17,   57],\n",
       "       [ 925,    8,  686,  152,  555,    3, 3583,    0,   88,    0],\n",
       "       [   0,    0,    0,    0,    0,   93,    0, 5660,    8,  239],\n",
       "       [  10,    3,   20,   23,   24,   21,   57,   14, 5825,    3],\n",
       "       [   0,    0,    2,    2,    0,   60,    2,  220,    6, 5708]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cnf_matrix = confusion_matrix(y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_FP = cv_cnf_matrix.sum(axis=0) - np.diag(cv_cnf_matrix) \n",
    "CV_FN = cv_cnf_matrix.sum(axis=1) - np.diag(cv_cnf_matrix)\n",
    "CV_TP = np.diag(cv_cnf_matrix)\n",
    "CV_TN = cv_cnf_matrix.sum() - (CV_FP + CV_FN + CV_TP)\n",
    "CV_FP = CV_FP.astype(float)\n",
    "CV_FN = CV_FN.astype(float)\n",
    "CV_TP = CV_TP.astype(float)\n",
    "CV_TN = CV_TN.astype(float)\n",
    "\n",
    "avg_cv_FP=0\n",
    "avg_cv_FN=0\n",
    "avg_cv_TP=0\n",
    "avg_cv_TN=0\n",
    "\n",
    "for i in CV_FP:\n",
    "    avg_cv_FP+=i\n",
    "    \n",
    "for i in CV_FN:\n",
    "    avg_cv_FN+=i\n",
    "    \n",
    "for i in CV_TP:\n",
    "    avg_cv_TP+=i\n",
    "\n",
    "for i in CV_TN:\n",
    "    avg_cv_TN+=i\n",
    "    \n",
    "avg_cv_FP = avg_cv_FP/10\n",
    "avg_cv_FN = avg_cv_FN/10\n",
    "avg_cv_TP = avg_cv_TP/10\n",
    "avg_cv_TN = avg_cv_TN/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6000,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0, 6000,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0, 6000,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0, 6000,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0, 6000,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0, 6000,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0, 6000,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 6000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0, 6000,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 6000]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see that it has 60000 TP because its the set it trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnf_matrix = confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FP = train_cnf_matrix.sum(axis=0) - np.diag(train_cnf_matrix) \n",
    "train_FN = train_cnf_matrix.sum(axis=1) - np.diag(train_cnf_matrix)\n",
    "train_TP = np.diag(train_cnf_matrix)\n",
    "train_TN = train_cnf_matrix.sum() - (train_FP + train_FN + train_TP)\n",
    "train_FP = train_FP.astype(float)\n",
    "train_FN = train_FN.astype(float)\n",
    "train_TP = train_TP.astype(float)\n",
    "train_TN = train_TN.astype(float)\n",
    "\n",
    "avg_train_FP=0\n",
    "avg_train_FN=0\n",
    "avg_train_TP=0\n",
    "avg_train_TN=0\n",
    "\n",
    "for i in train_FP:\n",
    "    avg_train_FP+=i\n",
    "    \n",
    "for i in train_FN:\n",
    "    avg_train_FN+=i\n",
    "    \n",
    "for i in train_TP:\n",
    "    avg_train_TP+=i\n",
    "\n",
    "for i in train_TN:\n",
    "    avg_train_TN+=i\n",
    "    \n",
    "avg_train_FP = avg_train_FP/10\n",
    "avg_train_FN = avg_train_FN/10\n",
    "avg_train_TP = avg_train_TP/10\n",
    "avg_train_TN = avg_train_TN/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[861,   0,  12,  31,   4,   1,  77,   0,  14,   0],\n",
       "       [  2, 971,   5,  17,   1,   1,   3,   0,   0,   0],\n",
       "       [  7,   2, 798,  13, 115,   0,  57,   0,   8,   0],\n",
       "       [ 17,   6,   8, 937,  18,   0,  14,   0,   0,   0],\n",
       "       [  1,   1,  64,  27, 862,   0,  42,   0,   3,   0],\n",
       "       [  0,   0,   0,   0,   0, 947,   0,  37,   5,  11],\n",
       "       [166,   1, 100,  28,  75,   0, 611,   0,  19,   0],\n",
       "       [  0,   0,   0,   0,   0,  13,   0, 937,   0,  50],\n",
       "       [  1,   1,   7,   0,   3,   1,  10,   3, 974,   0],\n",
       "       [  0,   0,   0,   0,   0,   7,   1,  41,   2, 949]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm = confusion_matrix(y_test, y_test_pred)\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnf_matrix = confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FP = test_cnf_matrix.sum(axis=0) - np.diag(test_cnf_matrix) \n",
    "test_FN = test_cnf_matrix.sum(axis=1) - np.diag(test_cnf_matrix)\n",
    "test_TP = np.diag(test_cnf_matrix)\n",
    "test_TN = test_cnf_matrix.sum() - (test_FP + test_FN + test_TP)\n",
    "test_FP = test_FP.astype(float)\n",
    "test_FN = test_FN.astype(float)\n",
    "test_TP = test_TP.astype(float)\n",
    "test_TN = test_TN.astype(float)\n",
    "\n",
    "avg_test_FP=0\n",
    "avg_test_FN=0\n",
    "avg_test_TP=0\n",
    "avg_test_TN=0\n",
    "\n",
    "for i in test_FP:\n",
    "    avg_test_FP+=i\n",
    "    \n",
    "for i in test_FN:\n",
    "    avg_test_FN+=i\n",
    "    \n",
    "for i in test_TP:\n",
    "    avg_test_TP+=i\n",
    "\n",
    "for i in test_TN:\n",
    "    avg_test_TN+=i\n",
    "    \n",
    "avg_test_FP = avg_test_FP/10\n",
    "avg_test_FN = avg_test_FN/10\n",
    "avg_test_TP = avg_test_TP/10\n",
    "avg_test_TN = avg_test_TN/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% accuracy for cross validation, 80% accuracy with decision tree, both worse than Categorical Naive Bayes which had 87% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest returns 88% accuracy from cv, and also 88% accuracy for the test set alone with the random forest classifier. RFC is better at not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88265\n",
      "52959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_train, cross_val_y_train_pred))\n",
    "\n",
    "print(accuracy_score(y_train, cross_val_y_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8847\n",
      "8847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specificity\n",
    "\n",
    "TN / (TN + FP) How sensitive is the classifier to the negative cases? - A highly specific test for cancer: if \"YES\" then you can be sure it's \"YES\". Closer to 1 means less false positives. 100% Specificity misses some true positives but in return provides no false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869611111111112"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_cv_TN/(avg_cv_TN+avg_cv_FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_train_TN/(avg_train_TN+avg_train_FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.987188888888889"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_test_TN/(avg_test_TN+avg_test_FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J48: 98% specificity for cv is incredible in comparison to 78% for Categorical Naive Bayes. Decision Tree Test also has 98%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFC: 99% sensitivity for cv and test, showing to be a better decision tree than the j48 because the accuracy is also higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall\n",
    "Recall is intuitevely the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The best value is 1, and the worst value is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision = TP / (TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43% for Categorical Naive Bayes, a big jump to 80% for J48 in both cross validation and test decision tree. A further jump to 88% for both cv and test set for RFC, random clssifier is doing really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88265"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train, cross_val_y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train, y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8847"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_test_pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recall = TP / (TP+FN)\n",
    "Similar to sensitivity (how sensitive is our classifier to the true cases? closer to 1 when theres no false negatives) with 100% sensitivity you catch all cases that could be true, so there will be more false postitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88265"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, cross_val_y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8847"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_test_pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall for Categorical Naive Bayes was .95 which was a really sensitive classifier, J48 it was .75 so less sensitive. This time around it has gone back up but not as high as naive bayes, to .88. This classifier is on the whole very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 = 2 / ((1 / precision) + (1 / recall)) = 2 x ((precision x recall) / (precision + recall)) = TP / (TP + ((FN + FP) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88265"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train, cross_val_y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8847"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_test_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_score(clf, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912469500000001"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_score, average='macro', multi_class='ovo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does Random Forest generalize well to the new data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RFC is better than the J48 algorithm across the board. This is because its training is more randomised, and therefore it generalises better, as it isn't relying on a particular dataset. RFC doesn't overfit or underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with various tree parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(random_state=42, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred2 = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[802,  81,  70,   1,   9,   1,   0,   1,  33,   2],\n",
       "       [ 10, 965,  21,   1,   0,   2,   0,   0,   1,   0],\n",
       "       [ 18,   3, 956,   0,   9,   0,   0,   1,  13,   0],\n",
       "       [282, 466,  63, 140,  28,   1,   0,   5,   2,  13],\n",
       "       [ 87,  28, 830,   1,  48,   0,   0,   1,   5,   0],\n",
       "       [  0,   8,   0,   2,   0, 138,   0, 580,  10, 262],\n",
       "       [271,  51, 621,   1,  13,   0,   1,   0,  42,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0, 897,   1, 101],\n",
       "       [  0,  12,  63,   4,   0,   6,   0,  27, 772, 116],\n",
       "       [  0,   1,   2,   1,   0,   0,   0,  82,   4, 910]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm2 = confusion_matrix(y_test, y_test_pred2)\n",
    "confusion_matrix(y_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnf_matrix2 = confusion_matrix(y_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FP2 = test_cnf_matrix2.sum(axis=0) - np.diag(test_cnf_matrix2) \n",
    "test_FN2 = test_cnf_matrix2.sum(axis=1) - np.diag(test_cnf_matrix2)\n",
    "test_TP2 = np.diag(test_cnf_matrix2)\n",
    "test_TN2 = test_cnf_matrix2.sum() - (test_FP2 + test_FN2 + test_TP2)\n",
    "test_FP2 = test_FP2.astype(float)\n",
    "test_FN2 = test_FN2.astype(float)\n",
    "test_TP2 = test_TP2.astype(float)\n",
    "test_TN2 = test_TN2.astype(float)\n",
    "\n",
    "avg_test_FP2=0\n",
    "avg_test_FN2=0\n",
    "avg_test_TP2=0\n",
    "avg_test_TN2=0\n",
    "\n",
    "for i in test_FP2:\n",
    "    avg_test_FP2+=i\n",
    "    \n",
    "for i in test_FN2:\n",
    "    avg_test_FN2+=i\n",
    "    \n",
    "for i in test_TP2:\n",
    "    avg_test_TP2+=i\n",
    "\n",
    "for i in test_TN2:\n",
    "    avg_test_TN2+=i\n",
    "    \n",
    "avg_test_FP2 = avg_test_FP2/10\n",
    "avg_test_FN2 = avg_test_FN2/10\n",
    "avg_test_TP2 = avg_test_TP2/10\n",
    "avg_test_TN2 = avg_test_TN2/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5629\n",
      "5629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred2))\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred2, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is low but still better than decision tree j48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9514333333333332"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_test_TN2/(avg_test_TN2+avg_test_FP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5629"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_test_pred2, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5629"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_test_pred2, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5629"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_test_pred2, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Depth Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the results of the major metrics that reducing the max depth of the decision tree to 2 still has a negative impact on the results even with RFC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Threshold for Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = RandomForestClassifier(random_state=42, ccp_alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(ccp_alpha=1.0, random_state=42)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred3 = clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm3 = confusion_matrix(y_test, y_test_pred3)\n",
    "confusion_matrix(y_test, y_test_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Threshold for Pruning Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifies as 7 everytime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting nodes (children not leafs) into x nodes, so a child node will be split into 6 here, and each of them 6 will either be split into another 6 or have 2 leaf nodes. My initial understanding tells me that a high split will return poor results because it will have too many to choose from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min split = 6 (deafault is 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = RandomForestClassifier(random_state=42, min_samples_split=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=6, random_state=42)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred4 = clf4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[855,   0,   8,  29,   2,   1,  94,   0,  11,   0],\n",
       "       [  3, 968,   6,  18,   1,   1,   2,   0,   1,   0],\n",
       "       [ 10,   1, 803,  10, 110,   0,  55,   0,  11,   0],\n",
       "       [ 19,   8,   8, 928,  22,   0,  15,   0,   0,   0],\n",
       "       [  0,   1,  62,  33, 858,   0,  43,   0,   3,   0],\n",
       "       [  0,   0,   0,   0,   0, 948,   0,  37,   5,  10],\n",
       "       [164,   1,  98,  24,  77,   0, 622,   0,  14,   0],\n",
       "       [  0,   0,   0,   0,   0,  18,   0, 932,   0,  50],\n",
       "       [  1,   1,   7,   0,   3,   1,   9,   2, 975,   1],\n",
       "       [  0,   0,   1,   0,   0,   6,   0,  40,   3, 950]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm4 = confusion_matrix(y_test, y_test_pred4)\n",
    "confusion_matrix(y_test, y_test_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnf_matrix4 = confusion_matrix(y_test, y_test_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FP4 = test_cnf_matrix4.sum(axis=0) - np.diag(test_cnf_matrix4) \n",
    "test_FN4 = test_cnf_matrix4.sum(axis=1) - np.diag(test_cnf_matrix4)\n",
    "test_TP4 = np.diag(test_cnf_matrix4)\n",
    "test_TN4 = test_cnf_matrix4.sum() - (test_FP4 + test_FN4 + test_TP4)\n",
    "test_FP4 = test_FP4.astype(float)\n",
    "test_FN4 = test_FN4.astype(float)\n",
    "test_TP4 = test_TP4.astype(float)\n",
    "test_TN4 = test_TN4.astype(float)\n",
    "\n",
    "avg_test_FP4=0\n",
    "avg_test_FN4=0\n",
    "avg_test_TP4=0\n",
    "avg_test_TN4=0\n",
    "\n",
    "for i in test_FP4:\n",
    "    avg_test_FP4+=i\n",
    "    \n",
    "for i in test_FN4:\n",
    "    avg_test_FN4+=i\n",
    "    \n",
    "for i in test_TP4:\n",
    "    avg_test_TP4+=i\n",
    "\n",
    "for i in test_TN4:\n",
    "    avg_test_TN4+=i\n",
    "    \n",
    "avg_test_FP4 = avg_test_FP4/10\n",
    "avg_test_FN4 = avg_test_FN4/10\n",
    "avg_test_TP4 = avg_test_TP4/10\n",
    "avg_test_TN4 = avg_test_TN4/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8839\n",
      "8839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred4))\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred4, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9871"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_test_TN4/(avg_test_TN4+avg_test_FP4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8839"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_test_pred4, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8839"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_test_pred4, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8839"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_test_pred4, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Split = 6 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it can be seen that with a sample split of 6, the accuracy is as good as it matches the decision tree accuracy, but is worse than the default for RFC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Split = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5 = RandomForestClassifier(random_state=42, min_samples_split=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=40000, random_state=42)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred5 = clf5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1000,    0,    0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm5 = confusion_matrix(y_test, y_test_pred5)\n",
    "confusion_matrix(y_test, y_test_pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Split = 40000 conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the above matrix that with a split of 40000 the algorithm performs poorly, as there are 10 classes and it is only classifying images as: class 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Leaf Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Leaf Nodes Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7 = RandomForestClassifier(random_state=42, max_leaf_nodes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_leaf_nodes=2, random_state=42)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred7 = clf7.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,  26,  26,   0, 872,   0,  36,  11,  28,   0],\n",
       "       [  0, 715,   0,   3, 273,   2,   0,   0,   0,   7],\n",
       "       [  0,   2,  45,   0, 926,   0,  21,   1,   5,   0],\n",
       "       [  0, 432,  15,  73, 410,   1,   9,   2,   4,  54],\n",
       "       [  0,   7,  11,   0, 973,   0,   3,   3,   3,   0],\n",
       "       [  0,   2,   0,   0,   0,   2,   0, 978,   4,  14],\n",
       "       [  0,  14,  33,   0, 875,   0,  44,   4,  28,   2],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 999,   0,   1],\n",
       "       [  0,   9,  25,   1,  45,  22,  42, 482, 372,   2],\n",
       "       [  0,   3,   0,   3,   1,   0,   1, 940,   3,  49]], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm7 = confusion_matrix(y_test, y_test_pred7)\n",
    "confusion_matrix(y_test, y_test_pred7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only 1 correct class 0 prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 200000 Leaf Nodes Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf8 = RandomForestClassifier(random_state=42, max_leaf_nodes=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_leaf_nodes=200000, random_state=42)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf8.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred8 = clf8.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[860,   0,  13,  35,   1,   1,  78,   0,  12,   0],\n",
       "       [  4, 971,   5,  15,   1,   1,   3,   0,   0,   0],\n",
       "       [  9,   1, 800,   8, 116,   0,  57,   0,   9,   0],\n",
       "       [ 21,   7,   8, 926,  21,   0,  17,   0,   0,   0],\n",
       "       [  1,   0,  62,  26, 865,   0,  43,   0,   3,   0],\n",
       "       [  0,   0,   0,   0,   0, 946,   0,  38,   5,  11],\n",
       "       [170,   1, 107,  32,  80,   0, 596,   0,  14,   0],\n",
       "       [  0,   0,   0,   0,   0,  16,   0, 930,   0,  54],\n",
       "       [  2,   1,   7,   0,   3,   2,   6,   2, 976,   1],\n",
       "       [  0,   0,   0,   0,   0,   7,   1,  39,   2, 951]], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm8 = confusion_matrix(y_test, y_test_pred8)\n",
    "confusion_matrix(y_test, y_test_pred8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 200K leaf nodes conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initially thought that it would be more accurate, but the matrix looks similar to that of the original algorithm. This will be because the max_split default is 2, and therefore the child nodes allow for the correct path, the only decision it has to make is on the leaf nodes, and it probably isn't using the full 200k leaf nodes allowed. If I were to change the max_split in combination with max leaf nodes to a really high number, the results would be bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test + 30% of Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_size = 512\n",
    "train_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_train.csv'))\n",
    "test_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_test.csv'))\n",
    "\n",
    "X_train = train_data[:, 1:785]\n",
    "y_train = train_data[:, 0]\n",
    "X_test = test_data[:, 1:785]\n",
    "y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_percent_X_train = X_train[0:18000]\n",
    "thirty_percent_y_train = y_train[0:18000]\n",
    "\n",
    "X_test_train = np.concatenate((X_test, thirty_percent_X_train), axis=0)\n",
    "y_test_train = np.concatenate((y_test, thirty_percent_y_train), axis=0)\n",
    "\n",
    "seventy_percent_X_train = X_train[18000:]\n",
    "seventy_percent_y_train = y_train[18000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n",
      "(28000,)\n",
      "(42000, 784)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_train.shape)\n",
    "print(y_test_train.shape)\n",
    "print(seventy_percent_X_train.shape)\n",
    "print(seventy_percent_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(seventy_percent_X_train, seventy_percent_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_y_train_pred = cross_val_predict(clf, seventy_percent_X_train, seventy_percent_y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cnf_matrix = confusion_matrix(seventy_percent_y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of 70% of Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8781190476190476\n",
      "36881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(seventy_percent_y_train, cross_val_y_train_pred))\n",
    "\n",
    "print(accuracy_score(seventy_percent_y_train, cross_val_y_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(seventy_percent_y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of Test + 30% of Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_train_pred = clf.predict(X_test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2480,    3,   37,   96,    3,    5,  225,    0,   19,    0],\n",
       "       [   3, 2698,   14,   52,    7,    1,   21,    0,    4,    0],\n",
       "       [  17,    1, 2234,   28,  313,    0,  146,    0,   20,    0],\n",
       "       [  53,   13,   24, 2596,   69,    0,   55,    0,    5,    0],\n",
       "       [   2,    5,  178,  122, 2302,    1,  118,    0,   10,    0],\n",
       "       [   0,    0,    0,    1,    0, 2675,    0,   86,    7,   26],\n",
       "       [ 433,    4,  349,   78,  256,    1, 1634,    0,   52,    0],\n",
       "       [   0,    0,    0,    0,    0,   49,    0, 2680,    4,  122],\n",
       "       [   5,    3,   14,    7,   11,   10,   31,    7, 2690,    4],\n",
       "       [   0,    0,    0,    0,    0,   30,    3,  104,    5, 2639]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm = confusion_matrix(y_test_train, y_test_train_pred)\n",
    "confusion_matrix(y_test_train, y_test_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8795714285714286\n",
      "24628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test_train, y_test_train_pred))\n",
    "\n",
    "print(accuracy_score(y_test_train, y_test_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_test_train, y_test_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy was the same as the original datasets. This shows the ability of the classifier to classify with less data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test + 60% of Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_size = 512\n",
    "train_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_train.csv'))\n",
    "test_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_test.csv'))\n",
    "\n",
    "X_train = train_data[:, 1:785]\n",
    "y_train = train_data[:, 0]\n",
    "X_test = test_data[:, 1:785]\n",
    "y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixty_percent_X_train = X_train[0:36000]\n",
    "sixty_percent_y_train = y_train[0:36000]\n",
    "\n",
    "X_test_train = np.concatenate((X_test, sixty_percent_X_train), axis=0)\n",
    "y_test_train = np.concatenate((y_test, sixty_percent_y_train), axis=0)\n",
    "\n",
    "fourty_percent_X_train = X_train[36000:]\n",
    "fourty_percent_y_train = y_train[36000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46000, 784)\n",
      "(46000,)\n",
      "(24000, 784)\n",
      "(24000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_train.shape)\n",
    "print(y_test_train.shape)\n",
    "print(fourty_percent_X_train.shape)\n",
    "print(fourty_percent_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(fourty_percent_X_train, fourty_percent_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_y_train_pred = cross_val_predict(clf, fourty_percent_X_train, fourty_percent_y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cnf_matrix = confusion_matrix(fourty_percent_y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of 40% Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.870625\n",
      "20895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(fourty_percent_y_train, cross_val_y_train_pred))\n",
    "\n",
    "print(accuracy_score(fourty_percent_y_train, cross_val_y_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(fourty_percent_y_train, cross_val_y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of Test + 60% Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_train_pred = clf.predict(X_test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3981,    4,   59,  176,   16,    6,  327,    0,   45,    0],\n",
       "       [   9, 4411,   20,  115,    6,    1,   30,    0,    3,    0],\n",
       "       [  27,    2, 3691,   43,  584,    1,  216,    0,   41,    0],\n",
       "       [  98,   18,   44, 4221,  108,    0,   96,    0,    9,    0],\n",
       "       [   6,    6,  341,  214, 3778,    1,  182,    0,   23,    0],\n",
       "       [   0,    0,    0,    0,    0, 4338,    0,  147,   22,   54],\n",
       "       [ 761,    7,  604,  129,  476,    2, 2576,    0,   98,    0],\n",
       "       [   0,    0,    0,    0,    0,  101,    0, 4304,    6,  234],\n",
       "       [   8,    5,   24,   13,   22,   19,   44,    9, 4421,    4],\n",
       "       [   0,    0,    2,    0,    0,   54,    1,  165,    9, 4382]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm = confusion_matrix(y_test_train, y_test_train_pred)\n",
    "confusion_matrix(y_test_train, y_test_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.871804347826087\n",
      "40103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test_train, y_test_train_pred))\n",
    "\n",
    "print(accuracy_score(y_test_train, y_test_train_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_test_train, y_test_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is similar again, slightly lower, but very much similar. Again, this shows the power of RFC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "\n",
    "X = X_train\n",
    "Y = y_train_0\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "clf = CategoricalNB()\n",
    "clf.fit(X, Y)\n",
    "CategoricalNB()\n",
    "CategoricalPredictions = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "countFalse = 0\n",
    "countTrue = 0\n",
    "\n",
    "for i in CategoricalPredictions:\n",
    "    if i == False:\n",
    "        countFalse += 1\n",
    "    elif i == True:\n",
    "        countTrue += 1\n",
    "        \n",
    "print(tabulate([['False', countFalse],['True', countTrue]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "87% accuracy - decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8706833333333334\n",
      "52241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = CategoricalPredictions\n",
    "y_true = y_train_0\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(accuracy_score(y_true, y_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46528,  7472],\n",
       "       [  287,  5713]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True negatives C0,0 is 46528 | False negatives C1,0 is 287 | True postivies C1,1 is 5713 | False postivies C0,1 is 7472. This is overly predicting true cases, but also predicts a good portion of negative cases with good accuracy. I'd say these results are neither amazing nor bad. My observation is that two items of clothing are very similar and so it is predicting them as the same item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777384214395509"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "46528 / (52380 + 7472)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.433295411452408"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9521666666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5955694553036226"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
