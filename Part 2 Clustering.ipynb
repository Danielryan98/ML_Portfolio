{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6da5f75",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "519ff5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import homogeneity_score\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b123f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_size = 512\n",
    "train_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_train.csv'))\n",
    "test_data = np.array(pd.read_csv(r'C:\\Users\\ryand\\Desktop\\Data Mining & ML\\Fashion\\fashion-mnist_test.csv'))\n",
    "\n",
    "X_train = train_data[:, 1:785]\n",
    "y_train = train_data[:, 0]\n",
    "X_test = test_data[:, 1:785]\n",
    "y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ae900b",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae46bb12",
   "metadata": {},
   "source": [
    "## Fit and Predict\n",
    "\n",
    "`fit_predict` Compute cluster centers and predict cluster index for each sample.\n",
    "\n",
    "\n",
    "\n",
    "`kmeans.fit_predict` <- Important to learn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit_predict\">Documentation Link</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40c239ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba4496d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 #10 classes\n",
    "kmeans = KMeans(n_clusters=k, random_state=42) #Define the kmeans algorithm with 10 clusters\n",
    "y_pred = kmeans.fit_predict(X_train) #Assign the images in the dataset a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36ea2215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2117de66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5012376251559566\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e92697",
   "metadata": {},
   "source": [
    "50% homogeneity score, so basically certain clusters contain images from multiple classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d338e25",
   "metadata": {},
   "source": [
    "Each instance was assigned to one of the 10 clusters. In the context of clustering, an instance’s label is the index of the cluster that this instance gets assigned to by the algorithm: this is not to be confused with the class labels in classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3a15ba36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred is kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb513b4",
   "metadata": {},
   "source": [
    "And the following 10 centroids (i.e., cluster centers) were estimated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cae7d469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.26415456e-18,  1.71013254e-03,  2.43693886e-02, ...,\n",
       "         5.94698589e-01,  4.28388200e-01,  9.19196238e-02],\n",
       "       [-9.21571847e-18,  7.11236625e-17, -4.09394740e-16, ...,\n",
       "         2.17603713e-14,  1.07691633e-14, -1.11022302e-15],\n",
       "       [ 1.83606557e-03,  4.19672131e-03,  2.15081967e-02, ...,\n",
       "         3.07540984e+00,  1.40708197e+00,  9.12786885e-02],\n",
       "       ...,\n",
       "       [ 2.65005963e-04,  9.80522062e-03,  6.63839936e-02, ...,\n",
       "         2.57002783e+00,  5.70557838e-01,  5.37962104e-02],\n",
       "       [-9.43255890e-18,  3.01904320e-03,  3.01904320e-03, ...,\n",
       "         2.78680910e-03,  2.32234092e-03, -9.43689571e-16],\n",
       "       [ 3.52208074e-03,  9.88891899e-03,  8.38526145e-02, ...,\n",
       "         7.27445137e-02,  2.53318884e-02,  3.11568681e-03]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05758831",
   "metadata": {},
   "source": [
    "Note that the `KMeans` instance preserves the labels of the instances it was trained on. Somewhat confusingly, in this context, the _label_ of an instance is the index of the cluster that instance gets assigned to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "88330384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelpred = kmeans.labels_\n",
    "labelpred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6215eec1",
   "metadata": {},
   "source": [
    "##### Initial Inertia - sum of squared distances - lower value is better - measures how internally coherent/logical clusters are (how close each instance is to its centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7b05a3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123913600595.06837"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b456a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kmeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3093e048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49876163409216845\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e7f0847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_train, labelpred)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681356d9",
   "metadata": {},
   "source": [
    "# Hard Clustering vs Soft Clustering\n",
    "Instead of assigning each instance to a single cluster, which is called hard clustering, it can be useful to give each instance a score per cluster, which is called soft clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ff0a4",
   "metadata": {},
   "source": [
    "`kmeans.transform` Transforms X to a cluster-distance space.\n",
    "\n",
    "`kmeans.transform` <- Important to learn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.transform\">Documentation Link</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ce6ebd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1833.59762914, 3241.17867176, 3483.62903025, ..., 2778.14122469,\n",
       "        2848.72641721, 2749.90343554],\n",
       "       [2205.54220106, 1788.20537288, 2102.94070011, ..., 2340.68040632,\n",
       "        1135.81627444, 3208.69661985],\n",
       "       [2706.70170562, 3597.59245592, 3484.99314509, ..., 2271.53666158,\n",
       "        3343.72104187, 1884.28590207],\n",
       "       ...,\n",
       "       [2831.28265477, 2979.82651792, 2921.98422809, ..., 2254.89135883,\n",
       "        2872.65942697, 2285.08420638],\n",
       "       [2009.86729265, 3047.69533014, 3181.56917383, ..., 2727.16946893,\n",
       "        2577.35448027, 3097.58176423],\n",
       "       [2094.32994589, 1799.18131203, 2774.22960594, ..., 2811.54510518,\n",
       "        2103.9915849 , 3440.84573969]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70f96f",
   "metadata": {},
   "source": [
    "### K-Means Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea0486",
   "metadata": {},
   "source": [
    "The K-Means algorithm is one of the fastest clustering algorithms, but also one of the simplest:\n",
    "* First initialize $k$ centroids randomly: $k$ distinct instances are chosen randomly from the dataset and the centroids are placed at their locations.\n",
    "* Repeat until convergence (i.e., until the centroids stop moving):\n",
    "    * Assign each instance to the closest centroid.\n",
    "    * Update the centroids to be the mean of the instances that are assigned to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce4bf9",
   "metadata": {},
   "source": [
    "The `KMeans` class applies an optimized algorithm by default. To get the original K-Means algorithm (for educational purposes only), you must set `init=\"random\"`, `n_init=1`and `algorithm=\"full\"`. These hyperparameters will be explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af25dee",
   "metadata": {},
   "source": [
    "Let's run the K-Means algorithm for 1, 2 and 3 iterations, to see how the centroids move around:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f896d297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='full', init='random', max_iter=3, n_clusters=5, n_init=1,\n",
       "       random_state=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_iter1 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=1, random_state=1)\n",
    "kmeans_iter2 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=2, random_state=1)\n",
    "kmeans_iter3 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=3, random_state=1)\n",
    "kmeans_iter1.fit(X_train)\n",
    "kmeans_iter2.fit(X_train)\n",
    "kmeans_iter3.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f0fe8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184019582123.818"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_iter1.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6cbec48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179756934571.2874"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_iter2.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c0c6d460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174954772443.16772"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_iter3.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaae6ee",
   "metadata": {},
   "source": [
    "### Inertia "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ccd77",
   "metadata": {},
   "source": [
    "To select the best model, we will need a way to evaluate a K-Mean model's performance. Unfortunately, clustering is an unsupervised task, so we do not have the targets. But at least we can measure the distance between each instance and its centroid. This is the idea behind the _inertia_ metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cb8ff83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123913600595.06837"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74998017",
   "metadata": {},
   "source": [
    "As you can easily verify, inertia is the sum of the squared distances between each training instance and its closest centroid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aad8771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123913600595.06718"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dist = kmeans.transform(X_train)\n",
    "np.sum(X_dist[np.arange(len(X_dist)), kmeans.labels_]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c14413",
   "metadata": {},
   "source": [
    "### Multiple Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3563bc",
   "metadata": {},
   "source": [
    "So one approach to solve the variability issue is to simply run the K-Means algorithm multiple times with different random initializations, and select the solution that minimizes the inertia. For example, here are the inertias of the two \"bad\" models shown in the previous figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "519fed1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='full', init='random', n_clusters=5, n_init=1, random_state=64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_rnd_init1 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                         algorithm=\"full\", random_state=44)\n",
    "kmeans_rnd_init2 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                         algorithm=\"full\", random_state=64)\n",
    "\n",
    "kmeans_rnd_init1.fit(X_train)\n",
    "kmeans_rnd_init2.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b76d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153169780725.82684"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_rnd_init1.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "271b59c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152974722478.92603"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_rnd_init2.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c77dae",
   "metadata": {},
   "source": [
    "As you can see, they have a higher inertia than the first \"good\" model we trained 123913600595.06837, which means they are probably worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff687bbc",
   "metadata": {},
   "source": [
    "When you set the `n_init` hyperparameter, Scikit-Learn runs the original algorithm `n_init` times, and selects the solution that minimizes the inertia. By default, Scikit-Learn sets `n_init=10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f355791a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='full', init='random', n_clusters=10, random_state=11)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_rnd_10_inits = KMeans(n_clusters=10, init=\"random\", n_init=10,\n",
    "                              algorithm=\"full\", random_state=11)\n",
    "kmeans_rnd_10_inits.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7d7ae950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123913634607.16289"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_rnd_10_inits.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf640e",
   "metadata": {},
   "source": [
    "As you can see, we end up with the initial model, which is certainly the optimal K-Means solution (at least in terms of inertia, and assuming $k=10$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be811b4e",
   "metadata": {},
   "source": [
    "### Finding the optimal number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002782c4",
   "metadata": {},
   "source": [
    "What if the number of clusters was set to 3, 8, 10, 15, 20, 30, 40, 50, and 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8be3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_dict = {}\n",
    "ssd_dict = {} #Sum of squared distance\n",
    "num_clusters = [3, 8, 10, 15, 20, 30, 40, 50, 100]\n",
    "\n",
    "for i in num_clusters:\n",
    "    kmeans_dict[i] = KMeans(n_clusters=i, random_state=42)\n",
    "\n",
    "for k, v in kmeans_dict.items():\n",
    "    kmeans_dict[k] = v.fit(X_train)\n",
    "\n",
    "\n",
    "for k, v in kmeans_dict.items():\n",
    "    ssd_dict[k] = v.inertia_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9645a615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inertia for kmeans n_clusters=3 is 179836700612.142\n",
      "Inertia for kmeans n_clusters=8 is 131872407195.94499\n",
      "Inertia for kmeans n_clusters=10 is 123913600595.06837\n",
      "Inertia for kmeans n_clusters=15 is 111191661691.78065\n",
      "Inertia for kmeans n_clusters=20 is 103885390772.46913\n",
      "Inertia for kmeans n_clusters=30 is 96312197247.72006\n",
      "Inertia for kmeans n_clusters=40 is 91242586597.38637\n",
      "Inertia for kmeans n_clusters=50 is 87986323767.76566\n",
      "Inertia for kmeans n_clusters=100 is 78649793094.36066\n"
     ]
    }
   ],
   "source": [
    "for k, v in ssd_dict.items():\n",
    "    print(\"Inertia for kmeans n_clusters=\" + str(k) + \" is \" + str(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c529c",
   "metadata": {},
   "source": [
    "Intertia is lower with more clusters. The more clusters there are, the closer each instance will be to its closest centroid, and therefore the lower the inertia will be. (The sum of squared distances is lower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76db0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dict = {}\n",
    "\n",
    "for k, v in kmeans_dict.items():\n",
    "    y_pred_dict[k] = (v.fit_predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0654e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fee8af2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity score for n_clusters=3 is 0.24660970169689944\n",
      "Homogeneity score for n_clusters=8 is 0.4732106848497327\n",
      "Homogeneity score for n_clusters=10 is 0.5012376251559566\n",
      "Homogeneity score for n_clusters=15 is 0.5983041448695275\n",
      "Homogeneity score for n_clusters=20 is 0.6109169456237296\n",
      "Homogeneity score for n_clusters=30 is 0.6317672786394706\n",
      "Homogeneity score for n_clusters=40 is 0.6565586359517213\n",
      "Homogeneity score for n_clusters=50 is 0.6687713236657383\n",
      "Homogeneity score for n_clusters=100 is 0.7110697693085035\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for k, v in y_pred_dict.items(): \n",
    "    print(\"Homogeneity score for n_clusters=\" + str(num_clusters[count]) + \" is \" + str(homogeneity_score(y_train, v)))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e76f3a",
   "metadata": {},
   "source": [
    "The more clusters there are, the better chance there is at having less cross over of classes, because classes are split into more clusters - homogeneity wants one class per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a047645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e8807d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_squared_distances = []\n",
    "for k, v in ssd_dict.items():\n",
    "    sum_of_squared_distances.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9370f3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_clusters, sum_of_squared_distances, 'bo-')\n",
    "plt.xlabel('Num. of clusters')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388c4dc",
   "metadata": {},
   "source": [
    "From this elbow plot we can see that the optimal number of clusters is somewhere between 10 and 25, so lets look at cluster totals 1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, and 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd11719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_dict = {}\n",
    "ssd_dict = {} #Sum of squared distance\n",
    "num_clusters = [1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 31]\n",
    "\n",
    "for i in num_clusters:\n",
    "    kmeans_dict[i] = KMeans(n_clusters=i, random_state=42)\n",
    "\n",
    "for k, v in kmeans_dict.items():\n",
    "    kmeans_dict[k] = v.fit(X_train)\n",
    "\n",
    "\n",
    "for k, v in kmeans_dict.items():\n",
    "    ssd_dict[k] = v.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b221408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_squared_distances = []\n",
    "for k, v in ssd_dict.items():\n",
    "    sum_of_squared_distances.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f033ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_clusters, sum_of_squared_distances, 'bo-')\n",
    "plt.xlabel('Num. of clusters')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d57a3b3",
   "metadata": {},
   "source": [
    "This didn't help too much, the initial thought is that 10 is the optimal because its a hard elbow, but if 10 wasn't a cluster argument, 11 would have been the initial thought. Cluster numbers 10 to 15 seem to be pretty optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f342a1bb",
   "metadata": {},
   "source": [
    "# Gaussian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec4d5554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.45305800e-03, 8.34162928e-03, 5.53776550e-02, ...,\n",
       "        2.32268630e+00, 3.35360396e-01, 9.84850424e-03],\n",
       "       [0.00000000e+00, 2.58352716e-03, 2.71489294e-03, ...,\n",
       "        3.45404446e+00, 1.70197516e+00, 1.68542306e-01]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(n_components=2, random_state=0).fit(X_train)\n",
    "gm.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3820e467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6255f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23569132598991122\n"
     ]
    }
   ],
   "source": [
    "y_pred = gm.predict(X_train)\n",
    "print(homogeneity_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe727aa",
   "metadata": {},
   "source": [
    "A low homogeneity score because i'v only allowed for two 'classes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d925927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.52833018e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.28440891e-03, 2.45573958e-02, 9.70873786e-02, ...,\n",
       "        1.33529412e+01, 6.04397487e+00, 7.98972016e-01],\n",
       "       ...,\n",
       "       [2.88065844e-02, 3.08641975e-02, 1.44032922e-01, ...,\n",
       "        1.94938272e+01, 8.68106996e+00, 4.60905350e-01],\n",
       "       [0.00000000e+00, 4.91159136e-04, 2.75049116e-02, ...,\n",
       "        2.95186640e-01, 2.15618861e-01, 6.58153242e-02],\n",
       "       [0.00000000e+00, 8.20170109e-02, 4.80558931e-01, ...,\n",
       "        9.79100851e+00, 2.33718104e+00, 2.66707169e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(n_components=10, random_state=0).fit(X_train)\n",
    "gm.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0ab4bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 5, 1, ..., 1, 2, 5], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17937a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46218185165346665\n"
     ]
    }
   ],
   "source": [
    "y_pred = gm.predict(X_train)\n",
    "print(homogeneity_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e0246",
   "metadata": {},
   "source": [
    "With 10 clusters the homogeneity improves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ba7266",
   "metadata": {},
   "source": [
    "# Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8222e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f533f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10cf142b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AffinityPropagation(random_state=42)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering = AffinityPropagation(random_state=42).fit(X)\n",
    "clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fdd2ebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 20,  0,  3, 31, 11, 37, 32, 33, 34, 10, 32,  7, 10, 39, 42, 27,\n",
       "       31, 19, 21, 18, 15, 17, 36, 19, 28,  0, 11, 41, 49,  7, 14, 15, 42,\n",
       "       37, 23, 32, 28, 24, 37,  0, 42, 16, 44, 44, 15, 46,  6, 41, 46, 23,\n",
       "       39, 24,  0, 48, 28, 23, 34,  8,  0,  7, 20, 17, 19,  1, 34,  1, 45,\n",
       "        4, 49,  2, 43, 48, 17, 11, 13, 37,  0, 18, 15,  9,  2, 33, 34, 48,\n",
       "        8,  6,  9, 18, 11, 10, 41,  3, 48, 41, 21, 41,  4,  2,  9, 12, 32,\n",
       "       44, 32, 40,  3, 30, 32, 39, 48, 10, 41, 24,  5, 16,  6, 17, 16,  9,\n",
       "        9, 46, 36, 44, 11, 40, 10, 21, 15,  7, 41, 41, 42, 40,  8, 41, 24,\n",
       "        8, 47, 32, 47, 44, 39, 21, 42,  9,  8, 32, 41, 23, 31,  6,  2, 17,\n",
       "       34,  4,  3,  6, 32, 39, 47, 22,  7, 21,  6,  3, 29, 23, 15,  6, 32,\n",
       "       10, 23, 24,  8, 44,  0, 47, 22, 17, 27,  2, 21, 42, 14, 38, 31, 32,\n",
       "       11, 19, 46, 18, 48, 41,  6,  7,  6, 32, 18, 17, 32, 37, 27, 32, 33,\n",
       "       41, 48, 33, 41,  8, 23, 11, 23, 24, 49, 46, 41, 40, 12,  9,  5, 21,\n",
       "       14, 10, 19, 37, 46, 38, 20, 36, 30,  4, 46, 28, 11, 25, 15, 14, 49,\n",
       "       37, 23,  1, 49, 27, 10, 32, 15, 41,  2, 37, 13, 33, 46, 32, 23,  9,\n",
       "       18, 23, 19, 21, 31, 14, 20, 47, 11, 20, 45, 28, 33, 40,  8, 47,  0,\n",
       "       23,  8, 41, 33, 32, 41, 32, 19, 48,  4, 33, 39, 47, 42, 31, 47, 15,\n",
       "        1, 30, 17, 41, 46, 32, 12, 33, 32,  7, 33, 17, 38, 22, 45, 37, 39,\n",
       "       42,  9,  0, 18, 48, 27, 12, 24, 41, 21, 10,  9, 23, 27,  8, 19, 41,\n",
       "       19, 46, 44, 32,  0, 15,  1, 46, 16, 25, 46, 13,  6, 32, 24, 27, 21,\n",
       "       14, 46, 37, 33, 39, 46, 36, 46, 44, 43, 38, 18, 32,  2, 17, 35, 33,\n",
       "       10, 41, 33, 24, 41, 38, 15, 36, 35, 40, 46,  2,  7, 37, 48, 48,  9,\n",
       "       32, 42, 19,  7, 33,  6, 41, 40,  1, 30, 27, 40, 14, 16, 42, 17,  1,\n",
       "       18, 19, 41,  8, 42, 41, 16, 19,  1, 44, 10, 36, 41, 18, 19, 36,  9,\n",
       "       36, 31, 19,  1, 39, 17, 20, 14, 19,  3,  8, 21, 47, 18, 43,  0, 22,\n",
       "       16,  3, 39,  9,  6, 41, 17, 43, 23,  1, 24, 46, 39, 23, 42,  9, 14,\n",
       "       42, 32,  2, 23, 32, 25, 41, 32,  2, 33, 38, 10, 40,  2, 36, 10, 10,\n",
       "       23, 24, 33, 17, 42, 31, 41, 14, 31, 20, 22, 25, 41,  3,  1,  3, 44,\n",
       "       23,  4,  9, 19, 32, 21, 10, 44, 37,  2, 10, 32, 42, 47, 35, 16, 15,\n",
       "       14, 32, 26, 19, 18,  9, 48, 12, 29, 49, 11,  0, 21,  3,  2, 39,  7,\n",
       "       48, 37,  8, 24, 20, 27, 41, 48, 15, 16, 32, 25, 48,  8,  7, 24, 37,\n",
       "        1, 28, 10, 11, 49, 28, 32, 15, 41, 18,  8, 21, 12, 29, 41, 41, 25,\n",
       "       41, 32, 37, 37,  4, 31, 48, 24,  6, 33, 41,  4, 11, 40, 45, 44, 30,\n",
       "       25, 15, 21, 42, 35,  7, 28, 18,  2, 39, 31, 33, 32, 47,  4,  9,  7,\n",
       "       21, 42, 46, 28, 33, 42, 43, 23, 18, 42, 37, 41, 20, 32,  4, 41,  1,\n",
       "       37, 11, 16, 17, 18, 10, 41,  0, 20, 35,  9, 37, 27, 33,  2, 17, 23,\n",
       "       42, 34, 32, 23,  1, 32, 14, 22, 24, 18,  6,  1, 35, 32,  3, 12, 41,\n",
       "       14, 33, 27, 42, 49, 18, 41, 46, 41, 48, 42, 47,  2, 18, 18, 41, 37,\n",
       "       28, 36, 12,  2, 41, 33, 46, 14, 37,  1,  8, 48, 25, 10, 33, 17, 14,\n",
       "        3, 19, 44, 20, 18, 37, 32, 25,  0, 32, 27, 23, 15, 38, 42,  7, 41,\n",
       "        7, 19, 41, 36, 36, 45, 36,  3, 25, 11, 34, 44, 32, 24,  1, 16,  0,\n",
       "        9, 41, 21, 48, 49, 22, 28, 39, 44, 48, 10, 23, 39,  4, 44, 37, 28,\n",
       "       42, 28, 11,  1,  7, 18, 33, 47, 47, 28, 21, 35, 20,  4,  4, 41, 14,\n",
       "       37, 17, 46, 43,  6, 49, 10, 46, 34,  0, 19, 19,  3, 39, 32, 27, 41,\n",
       "       16, 48, 48, 44, 32,  8, 36, 32,  5, 25, 37, 14, 45,  6, 34, 37,  0,\n",
       "       29, 17,  6, 49, 18, 47,  5, 28, 49, 40, 25, 31, 33, 31, 33,  3,  0,\n",
       "       41, 41,  9, 23, 41, 46, 18, 11, 14,  9, 41, 48, 40, 12,  9, 21, 49,\n",
       "       33, 24, 34, 42,  3, 23, 43, 15,  9,  3,  7, 42, 27, 21, 14, 11, 33,\n",
       "       15, 35, 29, 43, 32, 26, 20, 39, 41, 18, 18,  0, 35,  9, 24,  9, 15,\n",
       "       39, 11, 33, 38, 28, 14, 46, 14,  8, 44,  5,  5,  6, 41, 16, 42, 42,\n",
       "       19, 15, 36, 18, 32, 25, 44, 42, 31,  3, 45, 17, 33, 48, 46, 19, 32,\n",
       "       41, 28, 48, 18, 17,  3, 28, 20,  9, 27,  0, 24, 45, 42,  6, 20, 44,\n",
       "       42, 12, 23, 46, 39, 45, 48,  0, 36, 21,  1, 43,  5, 33, 33,  8,  3,\n",
       "       45, 47, 10, 48, 20, 20, 41, 15, 33, 44, 15,  3,  2, 28,  6, 15, 14,\n",
       "        7,  2,  7, 28, 15, 19, 12, 39, 33, 40, 46, 19,  3, 32, 19,  1, 14,\n",
       "       24, 11, 35, 23, 44, 47, 49, 28, 32, 23, 19, 15,  1, 25, 37, 34,  6,\n",
       "       33, 41,  4, 28, 20, 28, 42, 28, 39, 23, 32, 39, 44,  3, 48,  7,  5,\n",
       "       41, 32,  2, 49,  2, 11, 10,  3, 31, 41, 18, 19, 32,  2, 21, 42, 19,\n",
       "       46, 32, 47,  1, 42, 49, 41, 19,  2, 12,  5,  0,  4, 47],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "463bb5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6658886359078774\n"
     ]
    }
   ],
   "source": [
    "y_pred = clustering.predict(X)\n",
    "print(homogeneity_score(y_train[:1000], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da2a9a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 6, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f1186",
   "metadata": {},
   "source": [
    "# Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "clustering = MeanShift(bandwidth=2).fit(X)\n",
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efcfd4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clustering.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cbc18ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity_score(y_train[:1000], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692f50e",
   "metadata": {},
   "source": [
    "Almost homogeneous, this is because the mean shift has classified each cluster as a different label. So better homogeneous performance from mean shift, but it's obviosuly not true to labels, and the result is insignificantly pointless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39add8c",
   "metadata": {},
   "source": [
    "# Hierarchical | Agglomerative Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f2c2c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clustering = AgglomerativeClustering().fit(X)\n",
    "clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dab77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "575fd6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNT\n",
      "Zero: 2339\n",
      "One: 6511\n",
      "Two: 7626\n",
      "Three: 9659\n",
      "Four: 2588\n",
      "Five: 9062\n",
      "Six: 2980\n",
      "Seven: 7547\n",
      "Eight: 4306\n",
      "Nine: 7382\n",
      "Ten: 10\n",
      "Other: 0\n"
     ]
    }
   ],
   "source": [
    "zero = 0\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "four = 0\n",
    "five = 0\n",
    "six = 0\n",
    "seven = 0\n",
    "eight = 0\n",
    "nine = 0\n",
    "ten = 10\n",
    "other = 0\n",
    "\n",
    "for i in y_pred:\n",
    "    if i == 0:\n",
    "        zero+=1\n",
    "    elif i == 1:\n",
    "        one+=1\n",
    "    elif i == 2:\n",
    "        two+=1\n",
    "    elif i == 3:\n",
    "        three+=1\n",
    "    elif i == 4:\n",
    "        four+=1\n",
    "    elif i == 5:\n",
    "        five+=1\n",
    "    elif i == 6:\n",
    "        six+=1\n",
    "    elif i == 7:\n",
    "        seven+=1\n",
    "    elif i == 8:\n",
    "        eight+=1\n",
    "    elif i == 9:\n",
    "        nine+=1\n",
    "    elif i == 10:\n",
    "        ten+=1\n",
    "    else:\n",
    "        other+=1\n",
    "\n",
    "print(\"COUNT\")\n",
    "print(\"Zero: \" + str(zero))\n",
    "print(\"One: \" + str(one))\n",
    "print(\"Two: \" + str(two))\n",
    "print(\"Three: \" + str(three))\n",
    "print(\"Four: \" + str(four))\n",
    "print(\"Five: \" + str(five)) \n",
    "print(\"Six: \" + str(six))\n",
    "print(\"Seven: \" + str(seven)) \n",
    "print(\"Eight: \" + str(eight)) \n",
    "print(\"Nine: \" + str(nine))\n",
    "print(\"Ten: \" + str(ten))\n",
    "print(\"Other: \" + str(other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1254720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13807696066021058\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity_score(y_train[:1000], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b7d77",
   "metadata": {},
   "source": [
    "# Birch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb299b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Birch(n_clusters=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import Birch\n",
    "brc = Birch(n_clusters=None)\n",
    "brc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "00dd3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = brc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1791d6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity_score(y_train[:1000], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e4b777",
   "metadata": {},
   "source": [
    "Homogeneous because there are 0 clusters. Every single image is given a different label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c7981dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([963,  11, 531, 879, 781, 915, 827, 327, 678,   0, 861, 294, 365,\n",
       "       523, 652, 267, 964, 828, 759, 424,   1, 113, 760, 965, 829, 916,\n",
       "       532, 699, 158, 782, 357, 880, 114, 268, 830,  89, 201, 644, 581,\n",
       "       761, 533, 269, 917, 382, 383, 115, 653, 159, 295, 220,  12, 221,\n",
       "       645, 534, 490, 600,  13, 737, 384, 535,  48,  14, 700, 831,  49,\n",
       "       738,   2, 918,  90, 783, 919, 920, 471, 832, 601,  62, 762, 536,\n",
       "       222,  15, 784, 654, 602,   3, 472, 223, 116, 425, 202, 537, 921,\n",
       "       380, 881, 473, 160, 385, 203, 117, 922, 426, 966, 328, 701, 329,\n",
       "       427, 833, 967,  16, 224, 474, 582, 161, 646, 475, 923,  17, 702,\n",
       "       924, 428, 429, 225, 925, 270, 703, 785, 834, 296,  18,   4, 162,\n",
       "       163, 204, 430, 835,   5, 538, 431, 491, 297, 492, 882, 226, 386,\n",
       "       271, 786, 387, 298,   6,  19, 787, 118, 599, 704, 388,  63, 883,\n",
       "       119,   7, 227, 493, 366, 330, 205, 120, 884,  91,  20, 121, 122,\n",
       "       331, 739, 926, 539, 705, 389, 540, 494, 927, 836,  92, 655, 390,\n",
       "       272, 885, 968, 788, 332, 603, 789, 706, 228, 432, 164, 123, 333,\n",
       "       124, 334, 229, 837, 206, 790,  93, 335, 583, 299, 433, 584, 165,\n",
       "       391, 928, 656,  21, 647, 495, 657, 166, 434, 969, 435, 476, 436,\n",
       "       791, 862, 763, 792, 658, 970,  64, 585, 971, 381, 230, 541, 604,\n",
       "       929, 125, 838, 496, 793,  22,  23, 477,  94, 839,  24, 126, 127,\n",
       "       605, 840, 972, 542, 659, 336,  25, 497, 231, 930, 764, 437, 841,\n",
       "       842,  95, 498, 606,  96, 931, 679, 607, 438, 392, 439, 543,  26,\n",
       "       393, 167, 544, 337, 168, 300, 478, 440, 128, 608, 707, 499, 273,\n",
       "       794, 441, 129,  50, 932, 708, 169, 232, 301, 973, 609, 338, 367,\n",
       "       610, 795, 974, 933, 934, 843, 935, 274, 500, 545, 233, 501,  97,\n",
       "       975, 586, 170, 302, 863, 502,  27,  98, 394, 796, 171, 765, 709,\n",
       "       395, 303, 546,   8, 339, 660, 936, 740, 710, 976, 130, 304, 611,\n",
       "       131, 396, 886, 661, 844, 547, 711, 662, 612, 663, 712, 937, 977,\n",
       "       234, 305, 587, 713, 938, 613, 524, 172, 548, 614, 340, 978, 132,\n",
       "       664, 939, 442, 665, 666, 358, 845, 443, 503, 444, 359, 275, 797,\n",
       "       368, 615, 133, 134, 445,  51, 940,  65, 446, 846, 941, 276, 714,\n",
       "        52, 235, 766,  28, 715, 236, 173, 942, 767,  53, 887, 716, 680,\n",
       "       341, 207, 397, 616, 447, 681, 847, 798,  29, 717, 718,  66, 888,\n",
       "       768, 889, 398, 399, 448, 237, 943, 549, 369, 944, 864, 238, 799,\n",
       "       174, 175, 719, 979,  30,  31, 550, 239, 240,  32, 277, 400, 890,\n",
       "       208, 342, 588, 945, 343, 741, 176, 344, 980, 617, 981, 865, 449,\n",
       "       589, 682, 891, 866,  33, 590, 618, 525, 278, 800, 345, 892, 801,\n",
       "        67, 370, 742, 199, 867,  34, 893, 401,  99, 200, 450, 802, 346,\n",
       "       402, 720, 403, 848, 619, 868, 306, 279, 504, 371, 946, 135, 769,\n",
       "       209, 372, 770, 241, 803, 451, 982, 983, 505, 648, 551, 404, 894,\n",
       "       591, 721,  54, 405, 804, 406, 620,  68, 100, 177, 407,  35, 947,\n",
       "       307, 743, 506, 408,  36, 592, 771,  37, 552, 869, 621, 507, 553,\n",
       "       308, 136, 178, 242, 409, 309, 984, 101, 179, 137, 744, 180, 310,\n",
       "       805, 806,  38, 807, 508, 622, 181, 623, 182, 102, 722, 452, 948,\n",
       "       410, 985, 949,  39, 453, 210, 950, 360, 649, 243, 593, 723, 808,\n",
       "       554, 311, 509, 986, 809,  55, 411, 211, 624, 555, 556, 280, 951,\n",
       "       952, 244, 212, 772, 183,  40, 312,  41, 184,  56, 810, 625, 953,\n",
       "       526, 245, 870, 185, 557,  69,  70, 811, 812, 103, 626, 683, 724,\n",
       "       954, 281, 745, 282,  71,  57, 313, 895, 373, 684, 246, 104,  42,\n",
       "       955, 314, 896, 987, 186, 897, 627, 105, 283, 510, 247, 187, 725,\n",
       "       315, 454, 284, 511, 685, 248, 249, 188, 849, 628, 686, 988, 687,\n",
       "       189, 629, 667, 813, 850,  43, 412, 479, 746, 871, 688, 726, 898,\n",
       "       899, 773, 413,  72, 213, 851, 316, 747, 558, 317,  73,  44, 138,\n",
       "       989, 285,  58, 190, 361, 774, 191, 689, 690, 374, 668, 900, 748,\n",
       "       630, 749, 286, 287, 631, 347, 956, 559, 814, 192, 414, 455, 512,\n",
       "       375, 560, 727, 728, 456, 872,  74, 729, 139, 901, 852, 632, 214,\n",
       "       561, 633, 250,  59, 251, 562, 457, 513, 563, 318, 957,  75, 669,\n",
       "       990, 193, 902, 853, 730, 670, 991, 106, 480, 873, 252, 750, 564,\n",
       "       854, 775, 874, 253, 348, 107, 319,  76, 458, 481, 415, 320, 416,\n",
       "       691, 349, 417, 751, 855, 903, 376, 140, 752, 776, 565, 992, 856,\n",
       "       141, 514, 254, 459, 418, 650, 515, 460, 753, 815, 692, 816, 634,\n",
       "       875, 566, 194, 142, 817,  77, 195, 671, 255, 635, 876, 461, 321,\n",
       "       462, 463, 993, 818, 419, 516, 636, 637, 754, 288, 904,  78, 994,\n",
       "       143, 464, 905, 350, 256, 108,   9, 906, 651, 693, 144,  79, 109,\n",
       "       995, 322, 377,  80, 257, 145, 258, 259, 567, 958, 819, 694, 465,\n",
       "       351, 260, 527, 695, 996, 528, 857, 672, 858, 731, 289, 482, 483,\n",
       "       146, 147,  81, 290, 261, 777, 352, 696, 262, 323, 755, 420, 324,\n",
       "       859, 907, 959, 732, 638, 484, 673, 820, 215, 196, 568, 485, 263,\n",
       "       733, 908, 569,  82, 821, 110, 570, 571, 960, 421, 148,  83, 422,\n",
       "       291, 997,  60, 674, 264, 378, 486, 529, 594,  10, 353, 756, 487,\n",
       "       639, 572, 423, 909, 961, 517, 595, 518,  84,  85, 197, 149, 697,\n",
       "       910, 150, 911, 596, 573, 111, 151, 912, 379, 574, 362, 640, 152,\n",
       "       822, 998, 734, 575, 466, 675, 778, 913, 325, 823,  45, 877, 641,\n",
       "       530, 962,  46, 292, 467, 519, 576, 326,  86, 779, 153,  47, 757,\n",
       "       780, 758, 154, 577, 198, 112, 578,  87, 579, 216, 642, 265,  88,\n",
       "       217, 735, 266, 914, 468, 363, 488, 155, 354, 643, 520, 597, 676,\n",
       "       736, 878, 860, 355, 364, 824, 218, 598, 469, 293, 825, 677, 356,\n",
       "       470,  61, 219, 521, 156, 826, 698, 999, 489, 580, 157, 522])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815ef9e",
   "metadata": {},
   "source": [
    "* The advantage here is that it is unsupervised learning, clustering finds similarities in the images, which is almost like classifying without training which is impressive. This also saves time as training can take time.\n",
    "* Clustering with other algorithms that weren't K-means was problematic due to the amount of memory needed to do the computations, so I had to only select 1000 images.\n",
    "* Finding the optimal K value by a graph isn't the most precise method of finding an optimal value, it was quite hard to determine where the actual perfect elbow point was.\n",
    "* It shouldnt be compared to naive bayes because naive bayes gets the chance to train, and therefore will perform more accurate classifying in comparison to the clustering algorithms just finding similarities in images and grouping them together.\n",
    "* Naive Bayes classified an image as either something or not something, which is a different process to what takes place here where images are grouped together, K-means is not returning true or false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd47a7",
   "metadata": {},
   "source": [
    "# Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f9668fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_0 = (y_train == 0)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "\n",
    "X = X_train\n",
    "Y = y_train_0\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "clf = CategoricalNB()\n",
    "clf.fit(X, Y)\n",
    "CategoricalNB()\n",
    "CategoricalPredictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32c888fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  -----\n",
      "False  46815\n",
      "True   13185\n",
      "-----  -----\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "countFalse = 0\n",
    "countTrue = 0\n",
    "\n",
    "for i in CategoricalPredictions:\n",
    "    if i == False:\n",
    "        countFalse += 1\n",
    "    elif i == True:\n",
    "        countTrue += 1\n",
    "        \n",
    "print(tabulate([['False', countFalse],['True', countTrue]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "faa44796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8706833333333334\n",
      "52241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = CategoricalPredictions\n",
    "y_true = y_train_0\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(accuracy_score(y_true, y_pred, normalize=False))\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c05dc184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46528,  7472],\n",
       "       [  287,  5713]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8c4c557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777384214395509"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "46528 / (52380 + 7472)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146ac93",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8249e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.433295411452408"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03bf09",
   "metadata": {},
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c37649cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9521666666666667"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b30996",
   "metadata": {},
   "source": [
    "# F1 Score - balance between precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75d375fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5955694553036226"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b69b8e",
   "metadata": {},
   "source": [
    "# Homogeneity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47011cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44784891740454147\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
